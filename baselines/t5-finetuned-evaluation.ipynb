{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b35fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk bert-score datasets transformers pandas torch\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from transformers import LEDTokenizer, LEDForConditionalGeneration, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "from eval.eval import ClickbaitResolverEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa774c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "MODEL_PATH = \"../data/baseline_models/t5_finetuned/\"\n",
    "RESULT_PATH = \"../data/baseline_results/t5_finetuned/\"\n",
    "ENTRY_SET = [\"dev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(batch):\n",
    "    inputs_dict = tokenizer(batch[x_col], padding=\"max_length\", max_length=8192, return_tensors=\"pt\", truncation=True)\n",
    "    input_ids = inputs_dict.input_ids.to(\"cuda:0\")\n",
    "    attention_mask = inputs_dict.attention_mask.to(\"cuda:0\")\n",
    "    global_attention_mask = torch.zeros_like(attention_mask)\n",
    "    # put global attention on <s> token\n",
    "    global_attention_mask[:, 0] = 1\n",
    "\n",
    "    predicted_abstract_ids = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    batch[\"predicted_answer\"] = tokenizer.batch_decode(predicted_abstract_ids, skip_special_tokens=True)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "x_col = \"prepared_input\"\n",
    "label_col = \"answer\"\n",
    "\n",
    "os.makedirs(RESULT_PATH, exist_ok=True)\n",
    "\n",
    "#change this path to path of finetuned model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_PATH).to(\"cuda:0\").half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in ENTRY_SET:\n",
    "    val_df = pd.read_json(f\"{DATA_PATH}final_{entry}.json\")\n",
    "    val_df['prepared_input'] = val_df.apply(lambda row: f\"question: {row['title']}  context: {row['text']} </s>\", axis=1)\n",
    "\n",
    "    val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "    result = val_dataset.map(generate_answer, batched=True, batch_size=1)\n",
    "    result_df = result.to_pandas()\n",
    "    cleaned_result_df = result_df[[\"id\", \"predicted_answer\"]].rename(columns={'predicted_answer':'answer'}).astype({'id':'int32'})\n",
    "    cleaned_result_df.to_json(f\"{RESULT_PATH}{entry}.json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41444e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ClickbaitResolverEvaluator()\n",
    "\n",
    "for entry in ENTRY_SET:\n",
    "    agg_results, results = evaluator.run_file(f\"{RESULT_PATH}{entry}.json\", f\"{DATA_PATH}final_{entry}.json\")\n",
    "    evaluator.print_results(agg_results, results, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b7676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
